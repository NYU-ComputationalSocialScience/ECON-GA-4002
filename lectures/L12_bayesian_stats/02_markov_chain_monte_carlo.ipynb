{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Markov Chain Monte Carlo (MCMC)\n",
    "\n",
    "\n",
    "* Review\n",
    "* Central insight of MCMC\n",
    "* Metropolis-Hastings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review\n",
    "\n",
    "We briefly review some of the material we discussed previously to refresh prior to our discussion of Markov chain Monte Carlo methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Bayesian statistics**\n",
    "\n",
    "A Bayesian statistician builds a single model, $P(\\theta, Y)$ and updates their beliefs about $\\theta$ (a random variable) by conditioning on realizations of $Y$ (also a random variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The distribution $P(\\theta | Y)$, which expresses the distribution of the parameter $\\theta$ conditional on observed data, is known as the _posterior_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Bayes law tells us how to compute the posterior,\n",
    "\n",
    "$$P(\\theta | Y) = \\frac{\\overbrace{P(Y | \\theta)}^{\\text{likelihood}} \\overbrace{P(\\theta)}^{\\text{prior}}}{\\underbrace{P(Y)}_{\\text{Marginal distribution of $Y$}}}$$\n",
    "\n",
    "* _likelihood_: The conditional distribution that describes the random variable $Y$ conditional on a given $\\theta$\n",
    "* _prior_: The prior distribution is the marginal distribution that describes our beliefs about how likely certain values of $\\theta$ are\n",
    "* _Marginal distribution of $Y$_: The marginal distribution of $Y$ -- The marginal distribution of $Y$ is often ignored in Bayesian computations with the justification that the posterior is proportional to the product of the likelihood and prio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Using the posterior**: The posterior distribution is used to make inferences about how likely certain values of $\\theta$ are (conditional on what has been observed)\n",
    "\n",
    "- Credible sets: Let $\\tilde{y} \\sim f(Y | \\theta)$ then an $\\alpha$ credible set is a set $C_{\\alpha}$ such that $\\text{Prob}(\\theta \\in C_{\\alpha}) \\equiv \\int_{\\theta \\in C_{\\alpha}} P(\\theta | \\tilde{y}) d \\theta = \\alpha$\n",
    "  - Highest posterior interval\n",
    "  - Equal-tailed interval\n",
    "- Posterior allows us to answer questions such as, \"given the observed data, how likely is it that $\\theta > 0$?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Finding the posterior**: Seems easy, but it can difficult\n",
    "\n",
    "* Conjugate priors: For certain likelihoods, one can find a conjugate prior such that the posterior is in the same family of distributions as the prior. You can describe the posterior in terms of updated parameters\n",
    "* Markov chain Monte Carlo: What we will talk about today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Markov chains\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**What is a Markov chain?**\n",
    "\n",
    "A Markov chain is a stochastic pprocess that satisfies the Markov property which states $\\text{Prob}(x_t=x | \\{x_0, x_1, \\dots, x_{t-1}\\}) = \\text{Prob}(x_t=x | x_{t-1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Transition kernel**\n",
    "\n",
    "The transition kernel is defined by $\\phi(x, A) \\equiv \\text{Prob}(x_{t+1} \\in A | x_t = x) = \\int_{x_{t+1} \\in A} f(x_{t+1} | x_t) d x_{t+1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Stationary distribution**\n",
    "\n",
    "A stationary distribution, $\\phi^*(x)$, is a probability distribution such that $\\phi^*(A) = \\int_{y} \\phi^*(y) \\phi(y, A) dy$ -- That is, the probability of being in any subset of outcomes under the stationary distribution ($\\phi^*(A)$) is equivalent to the total probability of transitioning into that subset from anywhere else in the distribution ($\\int_{y} \\phi^*(y) \\phi(y, A) dy$).\n",
    "\n",
    "Under certain conditions (e.g. aperiodic and irreducible), a Markov chain has a unique stationary distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Central Idea of MCMC\n",
    "\n",
    "The central insight of MCMC is that, if we could sample from the posterior distribution, then we could approximate various statistics of interest using these samples\n",
    "\n",
    "However, unless we have chosen a very special case (e.g. conjugate-priors), we can't even determine the distribution class of the posterior, much less sample from it\n",
    "\n",
    "MCMC methods will build Markov chains that have a stationary distribution that corresponds to the posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Metropolis (et al.) - Hastings\n",
    "\n",
    "Versions of the algorithm were originally proposed in a pair of papers:\n",
    "\n",
    "1. _Equation of State Calculations by Fast Computing Machines_ by Nicholas Metropolis, Arianna W. Rosenbluth, Marshall Rosenbluth, Augusta H. Teller, Edward Teller\n",
    "2. _Monte Carlo Sampling Methods Using Markov Chains and Their Applications_ by W. K. Hastings\n",
    "\n",
    "This method can be used to sample from a probability distribution when direct sampling is difficult (such as with a non-conjugate posterior).\n",
    "\n",
    "The steps of the algorithm can be broken into a few steps:\n",
    "\n",
    "1. Initialize\n",
    "2. Iterate\n",
    "  - New candidate\n",
    "  - Acceptance ratio\n",
    "  - Accept or reject\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "Let $f^*(\\theta | \\tilde{y})$ be a function that is proportional to the desired probability distribution $f(\\theta | \\tilde{y})$.\n",
    "\n",
    "In particular, we will use\n",
    "\n",
    "$$f^*(\\theta | \\tilde{y}) \\equiv f(\\tilde{y} | \\theta) f(\\theta) = f(\\theta | \\tilde{y}) f(\\tilde{y}) \\propto \\frac{f(\\tilde{y} | \\theta) f(\\theta)}{f(\\tilde{y})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Step 1**: Initialize\n",
    "\n",
    "In order to initialize the algorithm, we need two components:\n",
    "\n",
    "1. An initial value $\\theta_0$ to start the Markov chain.\n",
    "  - One way to initialize the Markov chain is by drawing a sample from your prior!\n",
    "\n",
    "\n",
    "2. A proposal density, $g(\\theta' | \\theta_t)$ that will propose new values $\\theta'$ given curent value $\\theta_t$\n",
    "  - In what follows, we will assume $g$ is a symmetric distribution, i.e. $g(\\theta' | \\theta_t) = g(\\theta_t | \\theta')$, but this is not necessary\n",
    "  - It is common to choose $g(\\theta' | \\theta_t)$ to be a normal distribution with mean $\\theta_t$ (which makes the sequence of samples a random walk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def initial_theta(prior):\n",
    "    \"Draws a sample from the prior\"\n",
    "    return prior.rvs()\n",
    "\n",
    "\n",
    "def normal_proposal_density(theta, sigma):\n",
    "    \"\"\"\n",
    "    Proposes a new theta given the current theta and\n",
    "    standard deviation of the proposal density\n",
    "    \"\"\"\n",
    "    return st.norm(loc=theta, scale=sigma).rvs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Step 2**: Iterate\n",
    "\n",
    "The iteration step is itself composed of 3 steps:\n",
    "\n",
    "2.1 Generate a candidate proposal, $\\theta'$, by sampling from $g(\\theta' | \\theta_t)$\n",
    "\n",
    "2.2 Calculate the _acceptance ratio_, $\\alpha(\\theta', \\theta_t) \\equiv f(\\theta' | \\tilde{y}) / f(\\theta_t | \\tilde{y})$\n",
    "\n",
    "2.3 Accept or reject. Draw $u \\sim \\text{U}[0, 1]$ then accept proposal $\\theta'$ if $u \\leq \\alpha$, otherwise reject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def mh_step(theta, fstar, proposer):\n",
    "    \"The one-step iteration of the MH algorithm\"\n",
    "    # Propose a new theta\n",
    "    theta_proposal = proposer(theta)\n",
    "\n",
    "    # Compute the acceptance ratio\n",
    "    alpha = fstar(theta_proposal) / fstar(theta)\n",
    "\n",
    "    # Accept or reject\n",
    "    return (theta_proposal, 1) if np.random.rand() < alpha else (theta, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Wait... What is going on...**\n",
    "\n",
    "_Want_: Samples from $f(\\theta | \\tilde{y})$\n",
    "\n",
    "_What we are generating_: Samples from a Markov chain\n",
    "\n",
    "We won't do it today so that we can leave time for examples, but one can show that the stationary distribution for the Markov chain described above (sample from a symmetric distribution and accept with the probability given by the acceptance ratio) is the posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Putting it all together**\n",
    "\n",
    "We can then define a \"runner\" function that will take our steps and put them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def rw_mh_algorithm(prior, likelihood, sigma=0.5, Nburn=1_000, N=500):\n",
    "\n",
    "    # Draw initial theta\n",
    "    theta_0 = initial_theta(prior)\n",
    "\n",
    "    # Create the fstar and proposer func\n",
    "    fstar = lambda theta: prior.pdf(theta) * likelihood(theta)\n",
    "    proposer = lambda theta: normal_proposal_density(theta, sigma)\n",
    "\n",
    "    # Burn in the Markov chain\n",
    "    for t in range(Nburn):\n",
    "        theta_0, foo = mh_step(theta_0, fstar, proposer)\n",
    "\n",
    "    # Generate sample\n",
    "    accept_out = np.empty(N, dtype=int)\n",
    "    accept_out[0] = 1\n",
    "    theta_out = np.empty(N)\n",
    "    theta_out[0] = theta_0\n",
    "    for t in range(1, N):\n",
    "        theta_out[t], accept_out[t] = mh_step(\n",
    "            theta_out[t-1], fstar, proposer\n",
    "        )\n",
    "\n",
    "    return theta_out, accept_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example:\n",
    "\n",
    "It's always a good idea to begin with an example that we already know the answer to. Let's turn to one of our conjugate prior pairs and use it as a testing ground for our new algorithm.\n",
    "\n",
    "Let's return to our Beta-Binomial conjugate pair.\n",
    "\n",
    "* Prior: $f(p) = \\text{Beta}(\\alpha, \\beta)$\n",
    "* Likelihood: $f(k | p) = {n \\choose{k}} p^k (1 - p)^{n-k}$\n",
    "\n",
    "Then we know that the posterior is given by\n",
    "\n",
    "* Posterior: $f(p | k) = \\text{Beta}(\\alpha + k, \\beta + (n - k))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Likelhood parameter\n",
    "n = 5\n",
    "\n",
    "# Hyperparameters\n",
    "alpha, beta = 1.0, 1.0\n",
    "\n",
    "# Observed data\n",
    "k = 4\n",
    "\n",
    "prior = st.beta(alpha, beta)\n",
    "likelihood = lambda _p: st.binom(n, _p).pmf(k)\n",
    "posterior = st.beta(alpha + k, beta + (n-k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Visualization the algorithm**\n",
    "\n",
    "We plot a short history of steps below. In each of these steps, if a value is green, then it was an accepted proposal and if the value is red, then it was a rejected proposal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "p_mh, accept_mh = rw_mh_algorithm(prior, likelihood, sigma=0.05, Nburn=2_000, N=2_000)\n",
    "print(f\"Accepted {100*np.mean(accept_mh):0.2f} percent of samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "nstart = 5\n",
    "nsteps = 100\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "colors = np.array([\"red\", \"green\"])[accept_mh[nstart:nstart+nsteps]]\n",
    "ss = np.array([40.0, 15.0])[accept_mh[nstart:nstart+nsteps]]\n",
    "values = p_mh[nstart+1:nsteps+nstart+1]\n",
    "\n",
    "xvals = np.arange(nsteps)\n",
    "ax.scatter(xvals, values, c=colors, s=ss, alpha=0.75)\n",
    "\n",
    "# Set a non-white face color to help contrast colors\n",
    "ax.set_facecolor((0.95, 0.95, 0.95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Do you notice anything that seems concerning?\n",
    "\n",
    "* Samples are correlated\n",
    "\n",
    "We can cut down the correlation in two ways:\n",
    "\n",
    "1. Increase $\\sigma$ which means the movements are larger\n",
    "  - A rule of thumb is that the random walk Metropolis-Hastings algorithm should accept approximately 80% of the proposals\n",
    "\n",
    "\n",
    "2. Only keep every $n$th sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "p_mh, accept_mh = rw_mh_algorithm(prior, likelihood, sigma=0.09, Nburn=2_000, N=10_000)\n",
    "print(f\"Accepted {100*np.mean(accept_mh):0.2f} percent of samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "njump = 10\n",
    "p_mh_jump, accept_mh_jump = p_mh[::njump], accept_mh[::njump]\n",
    "\n",
    "nstart = 5\n",
    "nsteps = 100\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "colors = np.array([\"red\", \"green\"])[accept_mh_jump[nstart:nstart+nsteps]]\n",
    "ss = np.array([40.0, 15.0])[accept_mh_jump[nstart:nstart+nsteps]]\n",
    "values = p_mh_jump[nstart+1:nsteps+nstart+1]\n",
    "\n",
    "xvals = np.arange(nsteps)\n",
    "ax.scatter(xvals, values, c=colors, s=ss, alpha=0.75)\n",
    "\n",
    "# Set a non-white face color to help contrast colors\n",
    "ax.set_facecolor((0.95, 0.95, 0.95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Comparing the MH posterior with the analytical posterior**\n",
    "\n",
    "In the graph below we plot the pdf of the analytical posterior against a histogram of draws from the MH posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the histogram\n",
    "ax.hist(p_mh_jump, alpha=0.5, density=True, bins=25)\n",
    "\n",
    "# Plot the pdf\n",
    "x = np.linspace(0.0, 1.0, 500)\n",
    "ax.plot(x, posterior.pdf(x), linewidth=2.0, color=\"k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Other MCMC Algorithms\n",
    "\n",
    "There are many different MCMC algorithms (many of which perform better than the Metropolis-Hastings algorithm). For example,\n",
    "\n",
    "* Adaptive Metropolis-Hastings\n",
    "* Gibbs Sampler\n",
    "* Hamiltonian Monte Carlo (HMC)\n",
    "* No U-Turn Sampler (NUTS)\n",
    "\n",
    "We are particularly optimistic about the NUTS algorithm which is the default in many \"probabilistic programming languages\".\n",
    "\n",
    "We invite you to explore some of these algorithms with this (excellent) [online tool](https://chi-feng.github.io/mcmc-demo/app.html) develolped by [Chi Feng](https://github.com/chi-feng)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
