{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exponential Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "from ipywidgets import interact, IntSlider, FloatSlider\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Introduction:\n",
    "\n",
    "In probability theory and statistics, the **exponential distribution is the probability distribution of the time between events in a Poisson process**, i.e., a process in which events occur continuously and independently at a constant average rate.  \n",
    "  \n",
    "The other interpretation of **exponential distribution is a continuous analogue of the geometric distribution**. We use geometric distribution to describe the probability distribution of the number of trial before a certain event happened in a sequence of independent Bernoulli experiments. If a trial takes one unit of time, then the number of trial is just the *‘waiting time’*. We can cut the continuous time into infinite identical intervals and each of them is an independent Bernoulli experiment. In this sense, an exponential distribution is a continuous analogue of the geometric distribution, just like Poisson distribution is a limit of Bernoulli binomial distribution.  \n",
    "\n",
    "It can be applied to describe   the *'waiting time'* of before something happens:  \n",
    "* the waiting time between two telephone call\n",
    "* the life of the electronic component (the waiting time before the breakdown)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Details\n",
    "The shape of an exponential distribution depends on the rate parameter $\\lambda$, which is the reciprocal of the mean of the distribution. Intuitively, the average waiting time cannot be negative or 0, so its reciprocal rate parameter $\\lambda$ shall only be a positive real number. Similarly, because the exponential distribution describes the random variable of 'waiting time', its value can be any non-negative real number.\n",
    "  \n",
    "An exponential distribution is a continuous distribution on nonnegative real number ($ x \\in [0, +\\infty)$), with PMF and CDF as follows:\n",
    "\n",
    "**PDF:**  \n",
    "The probability density function (PDF) of exponential distribution with **rate parameter** $\\lambda >0$ is a monotone decreasing function given by\n",
    "  \n",
    "$$\n",
    "f(x;\\lambda) = \\begin{cases} \\lambda e ^ {-\\lambda x}, &  x \\geq 0 \\\\ \\quad0, & \\text{otherwise}  \\end{cases}\n",
    "$$\n",
    "  \n",
    "  \n",
    "**CDF:**  \n",
    "The cumulative distribution function (CDF) is a concave function that can be written in terms of:  \n",
    "  \n",
    "$$\n",
    "F(x;\\lambda) = \\begin{cases} 1 - e ^ {-\\lambda x}, &  x \\geq 0 \\\\ \\quad0, & \\text{otherwise}  \\end{cases}\n",
    "$$\n",
    "  \n",
    "  \n",
    "**Alternative parametrization:**  \n",
    "The exponential distribution is sometimes parametrized in terms of the **scale parameter** $\\beta = 1/\\lambda$:\n",
    "\n",
    "$$\n",
    "f(x;\\beta) = \\begin{cases} \\frac{1}{ \\beta } e ^ {-x / \\beta}, &  x \\geq 0 \\\\ \\quad0, & \\text{otherwise}  \\end{cases}\n",
    "$$  \n",
    "\n",
    "**Rate parameter $\\lambda$:** The mean and shape of the distribution is determined by the rate parameter $\\lambda$, it can take value from $(0, +\\infty)$.\n",
    "  \n",
    "**Caveat: Exponential Distribution in *scipy.stats*:**  \n",
    "In scipy.stats, the exponential distribution is defined using the scale parameter $\\beta = 1/\\lambda$. In this Jupyter Notebook I follows the representation of Durrett (2019) using rate parameter $\\lambda$ in math derivation. We should always remember to take the reciprocal of $\\lambda$ as the scale parameter when using scipy.stats.\n",
    "  \n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/0/02/Exponential_probability_density.svg/800px-Exponential_probability_density.svg.png' style=\"zoom:50%\" title=\"PDF of Exponential Distribution\">\n",
    "  \n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/b/ba/Exponential_cdf.svg/800px-Exponential_cdf.svg.png' style=\"zoom:50%\" title=\"CDF of Exponential Distribution\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def exponential_plot_pdf_cdf(λ):\n",
    "    erv = st.expon(scale = 1/λ)\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(9, 6))\n",
    "    \n",
    "    xvals = np.linspace(0, 10, 1000)\n",
    "    ax[0].plot(xvals, erv.pdf(xvals))\n",
    "    ax[0].set_title(\"Probability Distribution Function\")\n",
    "    \n",
    "    xvals = np.linspace(0, 10, 1000)\n",
    "    ax[1].plot(xvals, erv.cdf(xvals))\n",
    "    ax[1].set_title(\"Cumulative Distribution Function\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fs_lambda = FloatSlider(\n",
    "    value=1, min=0.1, max=5,\n",
    "    step=0.1, description=\"Rate $\\lambda$\",\n",
    "    style={\"description_width\": \"10%\"},\n",
    "    layout={\"width\": \"80%\"}\n",
    ")\n",
    "\n",
    "output = interact(exponential_plot_pdf_cdf, λ=fs_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties: Memoryless\n",
    "  \n",
    "Consider a simple case that waiting time between two telephone call follows an exponential distribution. I have already wait time $s$ after last call, and we are curious about the probability that it will last at least time $r$ before next call, or we are curious about $Prob \\{X > r + s | X > s \\}$. We can show that:  \n",
    "  \n",
    "$$\n",
    "\\begin{aligned}\n",
    "Prob \\{X > r + s | X > s \\} &= \\frac{Prob \\{X > r + s \\ and \\  X > s \\}}{Prob \\{ X > s \\}} \\\\\n",
    "&= \\frac{Prob \\{X > r + s \\}}{Prob \\{ X > s \\}} \\\\\n",
    "&= \\frac{e ^ { -\\lambda (r + s)}}{e ^ { -\\lambda s}} \\\\\n",
    "&= e ^ { -\\lambda r } \\\\\n",
    "&= Prob \\{ X > r\\}\n",
    "\\end{aligned}\n",
    "$$\n",
    "  \n",
    "  \n",
    "As we can see $Prob \\{X > r + s | X > s \\}$ is independent from s, and that means the distribution of waiting time is independent from how much time we have already waiting before. Actually, we have theorem:  \n",
    "  \n",
    "**Theorem (Memoryless of exponential distribution):**  \n",
    "A nonnegative continuous random variable X follows an exponential distribution **if and only if** for any real number r and s:  \n",
    "$$\n",
    "Prob \\{X > r + s | X > s \\} = Prob \\{ X > r\\}\n",
    "$$\n",
    "  \n",
    "The proof of only if direction have already been shown before.  The memoryless property of the exponential distribution follows directly from its relation to a Poisson process, and you can refer to Durrett (2019) for a more detailed explanation.  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install prettytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can check the memoryless by simple codes\n",
    "import prettytable as pt\n",
    "\n",
    "# rate parameter is 2, or scale parameter equals to 0.5\n",
    "λ = 2 \n",
    "erv = st.expon(scale = 1/λ)\n",
    "\n",
    "# consider r = 0.5, 1,and 2, while s = 1.\n",
    "r = np.array([0.5, 1, 2])\n",
    "s = 1\n",
    "\n",
    "# calculate the left hand side and right hand side of the above equation\n",
    "lhs = np.round((1 - erv.cdf(r + s))/ (1 - erv.cdf(s)), 5)\n",
    "rhs = np.round(1 - erv.cdf(r), 5)\n",
    "\n",
    "# table the outcomes\n",
    "tb = pt.PrettyTable()\n",
    "tb.field_names = [ ' ','Prob(x=0.5)', 'Prob(x=1)', 'Prob(x=2)']\n",
    "tb.add_row( ['Left Hand Side', lhs[0], lhs[1], lhs[2]] )\n",
    "tb.add_row(['Right Hand Side ', rhs[0], rhs[1], rhs[2]] )\n",
    "print(tb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Mean, Variance and Higher Moments: \n",
    "**1. Mean**:  \n",
    "$$\n",
    "\\mu = EX = \\int _{-\\infty }^{+\\infty } x f(x; \\lambda) dx = \\int _{0}^{+\\infty } \\lambda x e ^ {-\\lambda x} dx = \\frac{1}{ \\lambda }\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_vec = np.array([0.25, 0.5, 1, 2, 5])\n",
    "for lam in lam_vec:\n",
    "    erv = st.expon(scale = 1/lam)\n",
    "    print(f'Exponential distribution with rate parameter λ = {lam} has mean = {erv.mean()}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Variance**:  \n",
    "$$\n",
    "\\sigma^2 = DX = E(X^2) - (EX)^2 = \\int _{0}^{+\\infty } \\lambda x^2 e ^ {-\\lambda x} dx - \\frac{1}{ \\lambda^2 } = \\frac{1}{ \\lambda^2 }\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_vec = np.array([0.25, 0.5, 1, 2, 5])\n",
    "for lam in lam_vec:\n",
    "    erv = st.expon(scale = 1/lam)\n",
    "    print(f'Exponential distribution with rate parameter λ = {lam} has variance = {erv.var()}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Skewness, Kurtosis and Higher Moments**   \n",
    "  \n",
    "**Skewness**\n",
    "$$\n",
    "\\tilde{\\mu_3}= Skew(X) = E \\bigg[ \\bigg(\\frac{X - \\mu}{\\sigma} \\bigg)^3 \\bigg] = \\frac{E(X^3) - 3 \\mu \\sigma^2 - 3 \\mu^3}{\\sigma^3} = 2\n",
    "$$  \n",
    "  \n",
    "**Kurtosis and Excessive Kurtosis**\n",
    "$$\n",
    "\\tilde{\\mu_4}= Kurt(X) = E \\bigg[ \\bigg(\\frac{X - \\mu}{\\sigma} \\bigg)^4 \\bigg] = 9 \\\\\n",
    "Ex. Kurt(X) = Kurt(X) - 3 = 6 \n",
    "$$\n",
    "\n",
    "**Higher Moments**\n",
    "$$\n",
    "E[X ^ n] = \\frac{n!}{\\lambda^n}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples: Failure of Electronic Component\n",
    "\n",
    "  \n",
    "An electronic component can on average serve for 1000 hours, and the failure of the component occurs continuously and independently at the same rate, then: \n",
    "  \n",
    "What is the probability that one electronic component can serve more than 500 hours?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analytical Result:**\n",
    "\n",
    "Because the failure occurs continuously and independently, we know it follows an exponential distribution, in which rate parameter is given by:\n",
    "\n",
    "$$\n",
    "\\lambda  = \\frac{1}{ EX } = 0.001\n",
    "$$\n",
    "\n",
    "CDF is given by:\n",
    "\n",
    "$$\n",
    "F(x;\\lambda = 0.001) = \\begin{cases} 1 - e ^ {-0.001x} &  x \\geq 0 \\\\ \\quad0, & \\text{otherwise}  \\end{cases}\n",
    "$$\n",
    "\n",
    "Thus, the probability that one electronic component can work more than 500 hours is:\n",
    "\n",
    "$$\n",
    "Prob \\{X > 500\\} = 1- Prob \\{X \\leq 500\\} = 1 - F(500; \\lambda = 0.001) = e ^ {-0.5}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simulation Result:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the exponential distribution\n",
    "λ = 0.001\n",
    "erv = st.expon(scale = 1/λ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could take a single draw from this distribution to determine whether it work more than 500 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break_time = erv.rvs()\n",
    "print(break_time)\n",
    "break_time >= 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the mean of the distribution\n",
    "erv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the variance of the distribution\n",
    "erv.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can solve the problem using a Monte Carlo simulation. Consider a huge amount of independent identical components. The frequency shall converge to the probability according to the law of large number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_size = 1000000\n",
    "samples = erv.rvs(sim_size)\n",
    "\n",
    "print(f'Among {sim_size} times simulation, it success {np.sum(samples >= 500)}.')\n",
    "print(f'The probability calculate from the Monte Carlo simulation is {np.mean(samples >= 500)}.')\n",
    "print(f'The analytical result is {np.exp(-0.5)}.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the result, the Monte Carlo simulation give a pretty precise result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.kdeplot(samples,shade=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix: Relationship with Other Distribution\n",
    "\n",
    "<img src='./graph/relation.png' style=\"zoom:80%\">\n",
    "  \n",
    "**1. Exponential Distribution as *'Inverse'* of the Poisson Distribution**:   \n",
    "Poisson distribution is a discrete probability distribution that expresses the probability of a given number of events occurring in a fixed interval of time or space if these events occur with a known constant mean rate and independently of the time since the last event. A Poisson distribution with rate parameter $\\lambda \\in (0,+ \\infty)$ has possibility mass function (PMF):  \n",
    "  \n",
    "$$\n",
    "f(k; \\lambda) = Prob \\{X = k \\} = \\frac{ \\lambda^k e ^{-\\lambda} }{ k! } , \\ k =0, 1, 2, 3... \n",
    "$$\n",
    "  \n",
    "However, an exponential distribution is given inversely, that is, given two occurring events, we define the probability distribution of waiting time as an exponential distribution:\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "**2. Exponential Distribution as Continuous Analogue of the Geometric Distribution**:   \n",
    "As we have already introduce before, we use geometric distribution to describe the probability distribution of the number of failure $k$ before a certain event happened, in a sequence of independent Bernoulli experiments with probability of success $p \\in [0, 1]$. \n",
    "  \n",
    "$$\n",
    "f(k; p) = Prob \\{X = k \\} = (1 - p) ^ k p , \\ k =0, 1, 2, 3... \n",
    "$$\n",
    "  \n",
    "  \n",
    "If a trial takes one unit of time, then the number of trial is just the ‘waiting time’. We can cut the continuous time into infinite identical intervals and each of them is an independent Bernoulli experiment. In this sense, an exponential distribution is a continuous analogue of the geometric distribution, just like Poisson distribution is a limit of Bernoulli binomial distribution.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Exponential Distribution as Special Case of Gamma Distribution with $\\alpha = 1$**:   \n",
    "\n",
    "A gamma distribution is defined as a continuous distribution with PDF as follow, where shape parameter is $\\alpha \\in (0, +\\infty)$ and rate parameter is $\\lambda \\in (0, +\\infty)$: \n",
    "  \n",
    "$$\n",
    "f(x; \\alpha, \\lambda) = \\begin{cases} \\frac{ \\beta ^ \\alpha}{ \\Gamma(\\alpha) } x ^ { \\alpha - 1 } e ^ { -\\lambda x } , &  x \\geq 0 \\\\ \\quad0, & \\text{otherwise}  \\end{cases}\n",
    "$$\n",
    "  \n",
    "  \n",
    "or with CDF as follow:  \n",
    "  \n",
    "$$\n",
    "F(x; \\alpha, \\lambda) = \\begin{cases} \\frac{1}{ \\Gamma(\\alpha) } \\gamma(\\alpha, \\lambda x) , &  x \\geq 0 \\\\ \\quad0, & \\text{otherwise}  \\end{cases}\n",
    "$$\n",
    "  \n",
    "  \n",
    "By taking the shape parameter $\\alpha = 1$, we can find the gamma distribution degenerates to the exponential distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Exponential Distribution as Special Case of Weibull distribution with $k = 1$:**\n",
    "\n",
    "A Weibull distribution is defined as a continuous distribution with PDF as follows, where scale parameter is $\\beta \\in (0, +\\infty)$ and shape parameter is $k \\in (0, +\\infty) $: \n",
    "\n",
    "$$\n",
    "f(x; \\beta, k) = \\begin{cases} \\frac{k}{\\beta} (\\frac{x}{\\beta})^{k-1} e ^ { -(x/\\beta)^k } , &  x \\geq 0 \\\\ \\quad0, & \\text{otherwise}  \\end{cases}\n",
    "$$\n",
    "  \n",
    "  \n",
    "or with CDF as follow:  \n",
    "  \n",
    "$$\n",
    "F(x; \\beta, k) = \\begin{cases} 1 - e ^ {-(x/\\beta)^k}, &  x \\geq 0 \\\\ \\quad0, & \\text{otherwise}  \\end{cases}\n",
    "$$\n",
    "  \n",
    "  \n",
    "By thaking the shape parameter $k = 1$, we can find the Weibull distribution degenerates to the exponential distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: In creating this notebook, I referenced the \"Distribution Explorer\" material found at https://distribution-explorer.github.io/index.html, wikipedia https://en.wikipedia.org/wiki/Exponential_distribution, and *Durrett, R. (2019). Probability: theory and examples. Cambridge university press.* I certainly encourage others to find additional information there."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
