{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Optimization: An Introduction to the Nelder-Mead Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as opt\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D, proj3d\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "# Magics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "The [Nelder-Mead](http://www.ii.uib.no/~lennart/drgrad/Nelder1965.pdf) algorithm has historically been one of the most widely used optimization algorithms.\n",
    "\n",
    "Nelder-Mead searches for $x^*$ such that for $f: \\mathbb{R}^n \\rightarrow \\mathbb{R}$,\n",
    "\n",
    "$$x^* = \\arg \\min_{x} f(x)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Strengths**\n",
    "\n",
    "* No first or second derivatives required\n",
    "* Performs well on a large class of problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Weaknesses**\n",
    "\n",
    "* No first or second derivatives...\n",
    "* Potentially requires many evaluations of $f$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Key Components of the Algorithm\n",
    "\n",
    "The algorithm relies on 4 main operations on a simplex of points.  Before presenting the main algorithm, we will discuss these operations to simplify the process later.  The four operations are:\n",
    "\n",
    "* Reflection\n",
    "* Expansion\n",
    "* Contraction\n",
    "* Shrink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We will discuss these operations in the context of a concrete example.\n",
    "\n",
    "Consider the following simplex of points in 2-D. Let $\\Delta$ be a simplex that consists of the points $x_1 = (0, 0); x_2 = (2, 3); x_3 = (4, 0)$. We can then compute the center of mass $\\bar{x} = \\frac{1}{3} \\sum_{i=1}^3 x_i = (2, 1)$.\n",
    "\n",
    "We graph the points of our simplex and their center of mass below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "alpha, beta, gamma, delta = 1., 2., .5, .75\n",
    "x1, x2, x3 = np.array([0., 0.]), np.array([2., 3.]), np.array([4., 0.])\n",
    "xbar = (x1 + x2 + x3) / 3\n",
    "Delta = np.vstack([x1, x2, x3])\n",
    "offsets = [(-15, 10), (5, 5), (5, 5)]\n",
    "\n",
    "# init_simplex = Polygon(Delta, closed=True)\n",
    "fig, ax = plt.subplots(1, figsize=(10, 8))\n",
    "ax.set_xlim((-2, 7))\n",
    "ax.set_ylim((-5, 5))\n",
    "\n",
    "\n",
    "for ind, point in enumerate(Delta):\n",
    "    curr_x = r\"$x_{}$\"\n",
    "    curr_offset = offsets[ind]\n",
    "    ax.scatter(point[0], point[1], color=\"k\")\n",
    "    ax.annotate(curr_x.format(ind+1), xy=point, xytext=curr_offset, \n",
    "                textcoords='offset points', size=18)\n",
    "\n",
    "ax.scatter(xbar[0], xbar[1], color=\"k\")\n",
    "ax.annotate(r\"$\\bar{x}$\", xy=xbar, xytext=xbar, \n",
    "            textcoords='offset points', size=16)\n",
    "\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To facilitate a simple description of these operations, we sweep several formalities under the rug.\n",
    "\n",
    "* First, the point that has these operations applied to it is chosen within the algorithm (and depends on an $f$ which we have not specified), but we simply perform all of our operations on $x_2$.\n",
    "* Second, and perhaps more importantly, the center of mass used within the algorithm is not the center of mass of all $n+1$ points.\n",
    "* Finally, for aesthetic purposes, we use some nonstandard parameter values in the graphing of these operations ($\\alpha = 1$, $\\beta = 2$, $\\gamma=.5$, and $\\delta=.75$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Reflection\n",
    "\n",
    "The reflection operation creates a new point defined by reflecting a point across the center of mass of the simplex by $x_r := \\bar{x} + \\alpha (\\bar{x} - x_i)$, where $x_i$ is the point we are reflecting.\n",
    "\n",
    "Thus in our example, $x_r = \\bar{x} + \\alpha (\\bar{x} - x_2) = (2, 1) + \\alpha \\left( (2, 1) - (2, 3) \\right) = (2, -1)$.  We add the reflected point below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "xr = xbar + alpha*(xbar - x2)\n",
    "\n",
    "ax.scatter(xr[0], xr[1], color=\"b\")\n",
    "ax.annotate(r\"$x_r$\", xy=xr, xytext=xr,\n",
    "            textcoords='offset points', size=16)\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Expansion\n",
    "The expansion operation creates a new point by expanding the reflected point further away from $\\bar{x}$.  It is created by $x_e := \\bar{x} + \\beta (x_r - \\bar{x})$.\n",
    "\n",
    "In our example that $x_e = \\bar{x} + \\beta (x_r - \\bar{x}) = (2, 1) + \\beta \\left( (2, -1) - (2, 1) \\right) = (2, -3)$.  We add the expanded point below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "xe = xbar + beta*(xr - xbar)\n",
    "\n",
    "ax.scatter(xe[0], xe[1], color=\"g\")\n",
    "ax.annotate(r\"$x_e$\", xy=xe, xytext=xe,\n",
    "            textcoords='offset points', size=16)\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Contraction\n",
    "\n",
    "There are two types of contractions: outside and inside.  The operation of contraction is the opposite of the operation expanding in the sense that instead of expanded the reflected point out further, it draws it closer towards the center of mass.\n",
    "\n",
    "The outside contraction creates a new point by contracting towards the center of mass from the reflected point and is defined by $x_{oc} = \\bar{x} + \\gamma (x_r - \\bar{x})$.\n",
    "\n",
    "The inside contaction creates a new point by contracting towards the center of mass from the point $x_i$ that we reflected on and is defined by $x_{ic} = \\bar{x} - \\gamma (x_r - \\bar{x})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "xoc = xbar + gamma*(xr - xbar)\n",
    "xic = xbar - gamma*(xr - xbar)\n",
    "\n",
    "ax.scatter(xoc[0], xoc[1], color=\"r\")\n",
    "ax.scatter(xic[0], xic[1], color=\"r\")\n",
    "ax.annotate(r\"$x_{oc}$\", xy=xoc, xytext=xoc,\n",
    "            textcoords='offset points', size=16)\n",
    "ax.annotate(r\"$x_{ic}$\", xy=xic, xytext=xic,\n",
    "            textcoords='offset points', size=16)\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Shrink\n",
    "\n",
    "The shrink operation takes all but one of the points and draws them closer to that one point. In the algorithm, we won't be shrinking the points towards the point that we perform the reflection/expansion/contraction on, so we will use $x_1$ as the point towards which the points \"shrink.\"\n",
    "\n",
    "For every point except $x_1$, we create a new point $x_i^s = x_1 + \\delta (x_i - x_1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "xs2 = x1 + delta*(x2 - x1)\n",
    "xs3 = x1 + delta*(x3 - x1)\n",
    "\n",
    "ax.scatter(xs2[0], xs2[1], color=\"DarkOrange\")\n",
    "ax.scatter(xs3[0], xs3[1], color=\"DarkOrange\")\n",
    "ax.annotate(r\"$x_{2}^s$\", xy=xs2, xytext=xs2,\n",
    "            textcoords='offset points', size=16)\n",
    "ax.annotate(r\"$x_{3}^s$\", xy=xs3, xytext=xs3,\n",
    "            textcoords='offset points', size=16)\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Nelder-Mead Algorithm\n",
    "\n",
    "Now that we understand what each of the 4 operations within the Nelder-Mead algorithm do, we can discuss the actual algorithm.  As you read through the algorithm take note that the main idea is very simple:\n",
    "\n",
    "1. Order the points\n",
    "2. Create some new points\n",
    "3. Replace the point with the largest function value\n",
    "4. Repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. There are two ways to obtain the initial simplex.\n",
    "\n",
    "    1.1 The first way is to simply pass in a simplex $\\Delta$ as the guess.\n",
    "\n",
    "    1.2 The second is to pass in a single point, $x_0$, and create the simplex based around that point (we do this by using $x_0$ as one point of the simplex and by using $x_i := x_0 + e_i \\varepsilon$ for the $n$ other points)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. Once we have the simplex, we evaluate the function at each of the points in the simplex and sort the points such that $x_1 \\leq x_2 \\leq \\dots \\leq x_{n+1}$ and find $\\bar{x} := \\frac{1}{n} \\sum_{i=1}^n x_i$\n",
    "\n",
    "**Notice as we mentioned earlier, we are only taking the center point of the $n$ points with smallest function evaluations**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. If $|f(\\bar{x}) - f(x_1)| < \\varepsilon$ (or some other convergence metric of your choosing) then return $x_1$ as the minimum value, otherwise proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "4. Create a reflected point $x_r$ using $x_{n+1}$.\n",
    "\n",
    "    4.1 If $f(x_1) \\leq f(x_r) < f(x_n)$ then replace $x_{n+1}$ with $x_r$\n",
    "    \n",
    "    4.2 Return to step 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "5. Else if $f(x_r) < f(x_1)$ then create the expanded point $x_e$ using $x_{n+1}$.\n",
    "\n",
    "    5.1 If $f(x_e) < f(x_r)$ then replace $x_{n+1}$ with $x_e$\n",
    "    \n",
    "    5.2 Else if $f(x_r) < f(x_e)$ then replace $x_{n+1}$ with $x_r$.  \n",
    "    \n",
    "    5.3 Return to step 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "6. Else if $f(x_n) < f(x_r) < f(x_{n+1})$ then create the outside contraction point $x_{oc}$.\n",
    "\n",
    "    6.1 If $f(x_{oc}) < f(x_r)$ then replace $x_{n+1}$ with $x_{oc}$\n",
    "    \n",
    "    6.2 Else, shrink the points towards $x_1$\n",
    "    \n",
    "    6.3 Return to step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "7. Else if $f(x_{n+1}) < f(x_r)$ then create the inside contraction point $x_{ic}$.\n",
    "\n",
    "    7.1 If $f(x_{ic}) < f(x_r)$ then replace $x_{n+1}$ with $x_{ic}$\n",
    "    \n",
    "    7.2 Else, shrink the points towards $x_1$\n",
    "    \n",
    "    7.3 Return to step 2    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "That is the entire algorithm.\n",
    "\n",
    "As previously stated, you can see that it simply applies our main operations repeatedly until we converge.\n",
    "\n",
    "We will write a simple implementation of the algorithm below.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Chase Coleman\n",
    "Date: August 13, 2014\n",
    "\n",
    "This is a simple implementation of the Nelder-Mead algorithm\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def nelder_mead(f, x0, method=\"ANMS\", tol=1e-8, maxit=1e4, iter_returns=None):\n",
    "    \"\"\"\n",
    "    This is a naive python implementation of the nelder-mead algorithm.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    f : callable\n",
    "        Function to minimize\n",
    "    x0 : scalar(float) or array_like(float, ndim=1)\n",
    "        The initial guess for minimizing\n",
    "    method : string or tuple(floats)\n",
    "        If a string, should specify ANMS or NMS then will use specific\n",
    "        parameter values, but also can pass in a tuple of parameters in\n",
    "        order (alpha, beta, gamma, delta), which are the reflection,\n",
    "        expansion, contraction, and contraction parameters\n",
    "    tol : scalar(float)\n",
    "        The tolerance level to achieve convergence\n",
    "    maxit : scalar(int)\n",
    "        The maximimum number of iterations allowed\n",
    "\n",
    "\n",
    "    References :\n",
    "\n",
    "    Nelder, J. A. and R. Mead, \"A Simplex Method for Function\n",
    "    Minimization.\" 1965. Vol 7(4). Computer Journal\n",
    "\n",
    "    F. Gao, L. Han, \"Implementing the Nelder-Mead simplex algorithm with\n",
    "    adaptive parameters\", Comput. Optim. Appl.,\n",
    "\n",
    "    http://www.brnt.eu/phd/node10.html#SECTION00622200000000000000\n",
    "\n",
    "    \"\"\"\n",
    "    #-----------------------------------------------------------------#\n",
    "    # Set some parameter values\n",
    "    #-----------------------------------------------------------------#\n",
    "    init_guess = x0\n",
    "    fx0 = f(x0)\n",
    "    dist = 10.\n",
    "    curr_it = 0\n",
    "\n",
    "    # Get the number of dimensions we are optimizing\n",
    "    n = np.size(x0)\n",
    "\n",
    "    # Will use the Adaptive Nelder-Mead Simplex paramters by default\n",
    "    if method == \"ANMS\":\n",
    "        alpha = 1.\n",
    "        beta = 1. + (2./n)\n",
    "        gamma = .75 - 1./(2.*n)\n",
    "        delta = 1. - (1./n)\n",
    "    # Otherwise can use standard parameters\n",
    "    elif method == \"NMS\":\n",
    "        alpha = 1.\n",
    "        beta = 2.\n",
    "        gamma = .5\n",
    "        delta = .5\n",
    "    elif type(method) == tuple:\n",
    "        alpha, beta, gamma, delta = method\n",
    "\n",
    "\n",
    "    #-----------------------------------------------------------------#\n",
    "    # Create the simplex points\n",
    "    #-----------------------------------------------------------------#\n",
    "    simplex_points = np.empty((n+1, n))\n",
    "    pt_fval = [(x0, fx0)]\n",
    "\n",
    "    # Include the original value as one of the elements of the \n",
    "    # simplex\n",
    "    simplex_points[0, :] = x0\n",
    "    for ind, elem in enumerate(x0):\n",
    "        if np.abs(elem) < 1e-14:\n",
    "            curr_tau = 0.00025\n",
    "        else:\n",
    "            curr_tau = 0.05\n",
    "\n",
    "        curr_point = np.squeeze(np.eye(1, M=n, k=ind)*curr_tau + x0)\n",
    "\n",
    "        simplex_points[ind, :] = curr_point\n",
    "        pt_fval.append((curr_point, f(curr_point)))\n",
    "\n",
    "    if iter_returns is not None:\n",
    "        ret_points = []\n",
    "    else:\n",
    "        ret_points = None\n",
    "\n",
    "\n",
    "    #-----------------------------------------------------------------#\n",
    "    # The Core of The Nelder-Mead Algorithm\n",
    "    #-----------------------------------------------------------------#\n",
    "    while dist>tol and curr_it<maxit:\n",
    "        # 1: Sort and find new center point (excluding worst point)\n",
    "        pt_fval = sorted(pt_fval, key=lambda v: v[1])\n",
    "        xbar = np.zeros_like(x0)\n",
    "\n",
    "        for i in range(n):\n",
    "            xbar = xbar + (pt_fval[i][0])/(n)\n",
    "\n",
    "        if (iter_returns is not None) and (curr_it in iter_returns):\n",
    "            ret_points.append(pt_fval)\n",
    "\n",
    "        # Define useful variables\n",
    "        x1, f1 = pt_fval[0]\n",
    "        xn, fn = pt_fval[n-1]\n",
    "        xnp1, fnp1 = pt_fval[n]\n",
    "\n",
    "        # 2: Reflect\n",
    "        xr = xbar + alpha*(xbar - xnp1)\n",
    "        fr = f(xr)\n",
    "\n",
    "        if f1 <= fr < fn:\n",
    "            # Replace the n+1 point\n",
    "            xnp1, fnp1 = (xr, fr)\n",
    "            pt_fval[n] = (xnp1, fnp1)\n",
    "\n",
    "        elif fr < f1:\n",
    "            # 3: expand\n",
    "            xe = xbar + beta*(xr - xbar)\n",
    "            fe = f(xe)\n",
    "\n",
    "            if fe < fr:\n",
    "                xnp1, fnp1 = (xe, fe)\n",
    "                pt_fval[n] = (xnp1, fnp1)\n",
    "            else:\n",
    "                xnp1, fnp1 = (xr, fr)\n",
    "                pt_fval[n] = (xnp1, fnp1)\n",
    "\n",
    "        elif fn <= fr <= fnp1:\n",
    "            # 4: outside contraction\n",
    "            xoc = xbar + gamma*(xr - xbar)\n",
    "            foc = f(xoc)\n",
    "\n",
    "            if foc <= fr:\n",
    "                xnp1, fnp1 = (xoc, foc)\n",
    "                pt_fval[n] = (xnp1, fnp1)\n",
    "            else:\n",
    "                # 6: Shrink\n",
    "                for i in range(1, n+1):\n",
    "                    curr_pt, curr_f = pt_fval[i]\n",
    "                    # Shrink the points\n",
    "                    new_pt = x1 + delta*(curr_pt - x1)\n",
    "                    new_f = f(new_pt)\n",
    "                    # Replace\n",
    "                    pt_fval[i] = new_pt, new_f\n",
    "\n",
    "        elif fr >= fnp1:\n",
    "            # 5: inside contraction\n",
    "            xic = xbar - gamma*(xr - xbar)\n",
    "            fic = f(xic)\n",
    "\n",
    "            if fic <= fr:\n",
    "                xnp1, fnp1 = (xic, fic)\n",
    "                pt_fval[n] = (xnp1, fnp1)\n",
    "            else:\n",
    "                # 6: Shrink\n",
    "                for i in range(1, n+1):\n",
    "                    curr_pt, curr_f = pt_fval[i]\n",
    "                    # Shrink the points\n",
    "                    new_pt = x1 + delta*(curr_pt - x1)\n",
    "                    new_f = f(new_pt)\n",
    "                    # Replace\n",
    "                    pt_fval[i] = new_pt, new_f\n",
    "\n",
    "        # Compute the distance and increase iteration counter\n",
    "        dist = abs(fn - f1)\n",
    "        curr_it = curr_it + 1\n",
    "\n",
    "    if curr_it == maxit:\n",
    "        raise ValueError(\"Max iterations; Convergence failed.\")\n",
    "\n",
    "    if ret_points:\n",
    "        return x1, f1, curr_it, ret_points\n",
    "    else:\n",
    "        return x1, f1, curr_it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Rosenbrock Function\n",
    "\n",
    "One of the key tests for an optimization algorithm is Rosenbrock's \"banana function\" which is $f(x, y) := (a - x)^2 + b(y - x^2)^2$ which has a minimum at $(a, a^2)$.\n",
    "\n",
    "It is a tricky function because of nonconvexities and there are many points that are close to being a minimium.\n",
    "\n",
    "We graph the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Define Rosenbrock Function\n",
    "def rosenbrock(x, a=1, b=100):\n",
    "    \"\"\"\n",
    "    The minimum value of rosenbrock function is\n",
    "    (a, a**2)\n",
    "    \"\"\"\n",
    "    y = x[1]\n",
    "    x = x[0]\n",
    "    return (a - x)**2 + b*(y - x**2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-2.5, 2.5, 1000)\n",
    "y = np.linspace(-2.5, 2.5, 1000)\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "Z = rosenbrock([X, Y])\n",
    "\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122, projection=\"3d\")\n",
    "\n",
    "fig.suptitle(\"Rosenbrock Function\", size=24)\n",
    "\n",
    "# Color mesh\n",
    "ax1.set_facecolor(\"white\")\n",
    "ax1.pcolormesh(\n",
    "    X, Y, Z, cmap=matplotlib.cm.viridis,\n",
    "    norm=LogNorm(), shading=\"auto\"\n",
    ")\n",
    "ax1.scatter(1, 1, color=\"k\")\n",
    "ax1.annotate(\n",
    "    'Global Min', xy=(1, 1), xytext=(-0.5, 1.25),\n",
    "    arrowprops=dict(facecolor='black', shrink=0.05)\n",
    ")\n",
    "\n",
    "# Surface plot\n",
    "ax2.set_facecolor(\"white\")\n",
    "ax2.plot_surface(\n",
    "    X, Y, Z, norm = LogNorm(),\n",
    "    cmap=matplotlib.cm.viridis, linewidth=0\n",
    ")\n",
    "ax2.view_init(azim=65, elev=25)\n",
    "ax2.scatter(1., 1., 0., color=\"k\")\n",
    "xa, ya, _ = proj3d.proj_transform(1,1,0, ax2.get_proj())\n",
    "ax2.annotate(\n",
    "    \"Global Min\", xy = (xa, ya), xytext = (-100, 60),\n",
    "    textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
    "    arrowprops=dict(facecolor='black', shrink=0.05)\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Performance of the Nelder Mead\n",
    "\n",
    "Now that we have seen the objective function, we will try and use our algorithm to find the minimum of this function. \n",
    "\n",
    "To show the progress, we will plot some of the steps below -- In particular, we will plot iterations 0, 1, 2, 3, 4, 5, 10, 20, 50, 75, 90, and 95 as set by `iterstosee`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "iterstosee = [0, 1, 2, 3, 4, 5, 10, 15, 30, 45, 75, 90]\n",
    "x, fx, its, ret_tris = nelder_mead(rosenbrock, x0=np.array([-1.5, -1.]), tol=1e-12, iter_returns=iterstosee)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=6, ncols=2, figsize=(16, 24))\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Color mesh\n",
    "for i, curr_ax in enumerate(axs):\n",
    "    _iter = iterstosee[i]\n",
    "    curr_simplex = np.vstack([ret_tris[i][0][0], ret_tris[i][1][0], ret_tris[i][2][0]])\n",
    "    curr_ax.pcolormesh(\n",
    "        X, Y, Z, cmap=matplotlib.cm.viridis,\n",
    "        norm=LogNorm(), shading=\"nearest\"\n",
    "    )\n",
    "    curr_ax.set_title(f\"This is simplex for iteration {_iter}\")\n",
    "    curr_ax.scatter(curr_simplex[:, 0], curr_simplex[:, 1], color=\"k\", s=8)\n",
    "\n",
    "    \n",
    "    if _iter < 30:\n",
    "        curr_ax.set_xlim(-2.5, 2.5)\n",
    "        curr_ax.set_ylim(-2.5, 2.5)\n",
    "    elif iterstosee[i] < 75:\n",
    "        curr_ax.set_xlim(-0.25, 2.5)\n",
    "        curr_ax.set_ylim(-0.25, 2.5)\n",
    "    else:\n",
    "        curr_ax.set_xlim(0.75, 1.25)\n",
    "        curr_ax.set_ylim(0.75, 1.25)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The minimum value of the Rosenbrock banana function is $f(1, 1) = 0$.  I print the $x$ and $f(x)$ value below.  It seems that our minimization algorithm worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "printst = \"The minimization algorithm converged to x={} with a function value of f(x)={}\"\n",
    "print(\"\\n\" + printst.format(x, fx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "iterstosee = [0, 1, 2, 3, 15, 20, 25, 40, 55, 70, 85, 100]\n",
    "x, fx, its, ret_tris = nelder_mead(rosenbrock, x0=np.array([-1.5, 2.]), tol=1e-12, iter_returns=iterstosee)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=6, ncols=2, figsize=(16, 24))\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Color mesh\n",
    "for i, _ in enumerate(ret_tris):\n",
    "    curr_ax = axs[i]\n",
    "    _iter = iterstosee[i]\n",
    "    curr_simplex = np.vstack([ret_tris[i][0][0], ret_tris[i][1][0], ret_tris[i][2][0]])\n",
    "    curr_ax.pcolormesh(\n",
    "        X, Y, Z, cmap=matplotlib.cm.viridis,\n",
    "        norm=LogNorm(), shading=\"nearest\"\n",
    "    )\n",
    "    curr_ax.set_title(f\"This is simplex for iteration {_iter}\")\n",
    "    curr_ax.scatter(curr_simplex[:, 0], curr_simplex[:, 1], color=\"k\", s=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
