{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convex Optimization: Application to Energy Markets\n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "- Convex Optimization: Linear Programming\n",
    "- 2-day Energy Markets in US\n",
    "\n",
    "\n",
    "**Outcomes**\n",
    "\n",
    "- See how to map real-world financial constraints into linear program\n",
    "- Solve a 2-day portfolio optimization problem using linear programming\n",
    "- Understand the issue of \"corner-solutions\" in linear programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the line below if you do not have cvxpy installed\n",
    "# %pip install cvxpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import linprog\n",
    "import scipy.sparse as sparse\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Problem: Constrained Portfolio Optimization\n",
    "\n",
    "Chase and Spencer were given the following task in a private sector engagement we had with a client:\n",
    "\n",
    "We were asked to construct a profit maximizing portfolio of virtual bids, subject to the following risk constraints:\n",
    "\n",
    "- No more than 500 units per day\n",
    "- No more than 5 units long or short in any single hour\n",
    "- Hourly net neutral: number of longs + number of shorts = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In an early iteration of the final solution, we set up the portoflio choice problem as a linear program\n",
    "\n",
    "For the objective function we chose some approximation for the expected value of entering a long or short position\n",
    "\n",
    "The risk limits were encoded as inequality constraints in the inequality $A_{\\text{ub}} x \\le b_{\\text{ub}}$ and equation $A_{\\text{eq}} x = b_{\\text{eq}}$\n",
    "\n",
    "In this lecture we will work through the details of how we accomplished this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Preparation\n",
    "\n",
    "The file `spp_prices_sample.parquet` contains hourly prices for a subset of non-correlated nodes from 2020-01-01 to 2020-10-31\n",
    "\n",
    "Our goal today will be to use the data in this DataFrame to backtest a trading algorithm based on our linear programs for the month of October 2020\n",
    "\n",
    "To do this we will pretend that for the date October 1, 2020 we only have access to the data through the end of September 2020. \n",
    "\n",
    "Then for, say, October 10th we will assume we only observe data up until October 9th and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = (\n",
    "    pd.read_parquet(\"spp_prices_subset.parquet\")\n",
    "    .reset_index()\n",
    "    .assign(dt=lambda x: x[\"pricedate\"] + pd.Timedelta(hours=1) * (x[\"hour\"] - 1))\n",
    "    .set_index([\"pricedate\", \"hour\", \"node_id\"])\n",
    ")\n",
    "inds = [0, 1, 2, -3, -2, -1]\n",
    "df_full.iloc[inds, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = df_full.index.get_level_values(\"node_id\").nunique()\n",
    "n_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Choosing the State\n",
    "\n",
    "We'll stick to the mantra of \"choosing the state is an art\" and describe a key insight that allowed us to express this problem as a linear program\n",
    "\n",
    "Our goal is to choose a portfolio that is *balanced* hour by hour -- meaning we buy and sell an equal number of units each hour "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A linear program always has the constraint that the choice variable $x$ be non-negative\n",
    "\n",
    "In order to allow the linear program to enter a short position (buy a neagative amount in the day-ahead market),  we have two entries for each node and hour in our choice vector $x$: one for buying day-ahead and one for selling day-ahead\n",
    "\n",
    "Thus, our choice vector will be length `n_nodes * n_hours * 2`, which for our example is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hours = 24\n",
    "n_choice = n_nodes * n_hours * 2\n",
    "n_choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Objective function\n",
    "\n",
    "For the objective function, we need to capture the expected value of entering into each position\n",
    "\n",
    "Because we are constrained to be net-zero each hour, the contribution of the marginal cost of energy will be zero\n",
    "\n",
    "We'll focus on the cost of congestion and loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Define the quantity:\n",
    "\n",
    "$$rtda_{i,t} \\equiv rtmcc_{i,t} + rtmcl_{i,t} - damcc_{i,t} - damcl_{i,t},$$\n",
    "\n",
    "Which represents the spread between real time and day ahead congestion and loss at node $i$ in hour $t$\n",
    "\n",
    "Let $x^+_{i,t}$ be the number of units long at node $i$ in hour $t$\n",
    "\n",
    "The payoff for entering this position is equal to $$rtda_{i,t} \\cdot x^+_{i,t}$$\n",
    "\n",
    "Similarly let $x^-_{i,t}$ represent units short at node $i$ and hour $t$ with profits equal to $$-rtda_{i,t}\\cdot x^-_{i,t}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We need to approximate this payoff in order to form the vector $c$ in the objective function of our linear program\n",
    "\n",
    "We will first compute the quantity $rtda_{i,t}$ for all rows in our training dataset `df_full`\n",
    "\n",
    "Then we will use the 30-day-trailling moving average of the hour-by-hour payoffs for each node..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df_full[\"rtda\"] = df_full.eval(\"rtmcc + rtmcl - damcc - damcl\")\n",
    "df_full[\"rtda_rolling_30d\"] = (\n",
    "    df_full\n",
    "    .reset_index()\n",
    "    .groupby([\"node_id\", \"hour\"])\n",
    "    [[\"pricedate\", \"rtda\"]]\n",
    "    .apply(lambda x: x.set_index(\"pricedate\").rolling(\"30d\").mean().shift())\n",
    "    .swaplevel(\"pricedate\", \"node_id\")\n",
    "    .sort_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes: \n",
    "\n",
    "- We apply a `shift` after doing the 30 day moving average because when submitting day-ahead bids for day `t` we don't know all hours of day `t` real time prices. We only have full observation for hours in day `t-1`\n",
    "- We `swaplevel` to let pandas align data for us using the index of `df_full` and the new 30-day column\n",
    "- The `rtda_rolling_30d` for a particular date will be the vector $c$ associated with a short position across all nodes an hours for that date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We will define $x^+$ as a vector of all long positions, $x^-$ as the vector of all long positions and define\n",
    "\n",
    "$$x \\equiv \\begin{bmatrix}x^+ \\\\ x^-\\end{bmatrix},$$\n",
    "\n",
    "As our vector of positions\n",
    "\n",
    "Furthermore, we will impose that both $x^+$ and $x^-$ are lexographically sorted by hour and the node_id:\n",
    "\n",
    "$$x^+ = \\begin{bmatrix}x^+_{1,1} \\\\x^+_{2,1} \\\\ \\vdots \\\\ x^+_{n_\\text{nodes},1} \\\\ x^+_{1,2} \\\\ x^+_{2,2} \\\\ \\vdots \\\\ x^+_{n_\\text{nodes},2} \\\\ \\vdots \\\\ x^+_{n_\\text{nodes},24} \\end{bmatrix}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We construct a series `c_full` that adheres to this ordering convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note sign on the `rtda_rolling_30d`. It will correspond to \n",
    "# minus profits so we are ready for linprog to minimize negative profits\n",
    "c_full = (\n",
    "    pd.concat([\n",
    "        df_full[\"rtda_rolling_30d\"].rename(\"cplus\"), \n",
    "        -df_full[\"rtda_rolling_30d\"].rename(\"cminus\")\n",
    "    ], axis=1)\n",
    "    .stack()\n",
    "    .rename_axis(index=[\"pricedate\", \"hour\", \"node_id\", \"plus_minus\"])\n",
    "    .reorder_levels([\"pricedate\", \"plus_minus\", \"hour\", \"node_id\"])\n",
    "    .sort_index()\n",
    ")\n",
    "c_full.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Constraints\n",
    "\n",
    "We can map each of the risk constraints into rows of a constraint matrix $A$ and vector $b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Total volume $\\le$ 500\n",
    "\n",
    "We need a single row of $A$ equal to all ones. \n",
    "\n",
    "The corresponding element in $b$ will be 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_volume = np.ones(n_choice).reshape((1, -1))\n",
    "b_volume = np.array([500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 5 unit limit at each node and location\n",
    "\n",
    "The second limit is that we can't have more than 5 units in any single position\n",
    "\n",
    "This limit can be expressed by the identity matrix and a vector full of 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_nodal_volume = sparse.eye(n_choice)\n",
    "b_nodal_volume = np.ones(n_choice) * 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Hourly net zero\n",
    "\n",
    "Finally, we have a constraint that we must have a net zero position in each hour\n",
    "\n",
    "This is the most difficult constraint for which to construct the rows of $A$ and $b$\n",
    "\n",
    "Because we need the net position to be strictly equal to zero, we'll use the `A_eq` and `b_eq` arguments to `linprog` for expressing this risk limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Consider a row of matrix $A$ specifying that we need to be net 0 for hour 10\n",
    "\n",
    "We need to set this row entirely equal to 0, except for a 1 for all $x^+$ and a -1 for all $x^-$\n",
    "\n",
    "This will cause us to compute $\\sum_{i} x^+_{i,10} - x^-_{i,10}$\n",
    "\n",
    "With a corresponding entry of $b$ of 0, this imposes the net-zero exposure constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Our strategy for computing these rows of $A$ will be to use the fact that the pandas index is already lexographically sorted by hour and node_id, and do some boolean computations on the `hour` level of the index to identify columns that pertain to each hour:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_eq = np.zeros((24, n_choice))\n",
    "\n",
    "# get all hours for a specific day and subtract one to go from 0..23\n",
    "c_hours = (c_full.loc[\"2020-10-01\"].reset_index()[\"hour\"] - 1).to_numpy()\n",
    "scale_replacement = {\"cminus\": -1, \"cplus\": 1}\n",
    "scale = (\n",
    "    c_full.loc[\"2020-10-01\"]\n",
    "    .reset_index()\n",
    "    [\"plus_minus\"]\n",
    "    .replace(scale_replacement)\n",
    "    .to_numpy()\n",
    ")\n",
    "for hour in range(24): \n",
    "    A_eq[hour, :] = (c_hours == hour) * scale\n",
    "    \n",
    "A_eq = sparse.csr_matrix(A_eq)\n",
    "b_eq = np.zeros(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Solving the Linear Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def solve_for_date(date):\n",
    "    # extract c vector for chosen date\n",
    "    c_date = c_full.loc[date]\n",
    "    c = c_date.to_numpy()\n",
    "\n",
    "    # build constraint matrices\n",
    "    A_ub = sparse.vstack([A_volume, A_nodal_volume])\n",
    "    b_ub = np.concatenate([b_volume, b_nodal_volume])\n",
    "\n",
    "    # using cvxpy for performance gain.\n",
    "    # alternative is to pass all the arrays constructed above\n",
    "    # to scipy.optimize.linprog using the argument names we\n",
    "    # assigned to these variables\n",
    "    x = cp.Variable(n_choice)\n",
    "    prob = cp.Problem(\n",
    "        cp.Minimize(c @ x),\n",
    "        [\n",
    "            A_ub @ x <= b_ub,\n",
    "            A_eq @ x == b_eq,\n",
    "            x >= np.zeros(n_choice)\n",
    "        ]\n",
    "    )\n",
    "    prob.solve()\n",
    "    \n",
    "    bids = (\n",
    "        pd.Series(x.value, index=c_date.index, name=\"bid\")\n",
    "        .reset_index()\n",
    "        .assign(pricedate=date)\n",
    "    )\n",
    "        \n",
    "    # unpack constraints.\n",
    "    \n",
    "    # give them a helpful label so we can interpret them later\n",
    "    nodal_volume_labels = [\n",
    "        \"node{node_id}_hour{hour}\".format(**x) \n",
    "        for x in c_date.reset_index().to_dict(orient=\"records\")\n",
    "    ]\n",
    "    cons_id = (\n",
    "        [\"volume\"]*b_volume.size + \n",
    "        nodal_volume_labels + \n",
    "        [f\"net_zero_hour_{i}\" for i in range(1, 25)]\n",
    "    )\n",
    "    \n",
    "    # package them up\n",
    "    shadows = pd.Series(\n",
    "        np.concatenate([x.dual_value for x in prob.constraints[:2]]),\n",
    "        name=\"shadow_price\"\n",
    "    ).to_frame().assign(pricedate=date)\n",
    "    shadows[\"cons_id\"] = cons_id\n",
    "    \n",
    "    # return both\n",
    "    return bids, shadows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "bid_shadows = []\n",
    "for d in pd.date_range(\"2020-10-01\", \"2020-10-31\"):\n",
    "    print(f\"solving for {d}\")\n",
    "    bid_shadows.append(solve_for_date(date=d))\n",
    "\n",
    "bids, shadows = zip(*bid_shadows)\n",
    "all_bids = pd.concat(bids)\n",
    "all_shadows = pd.concat(shadows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "output = (\n",
    "    all_bids\n",
    "    .reset_index()\n",
    "    .assign(\n",
    "        scale=lambda x: x[\"plus_minus\"].replace(scale_replacement),\n",
    "        bidvolume=lambda x: x.eval(\"scale*bid\")\n",
    "    )\n",
    "    .merge(df_full[\"rtda\"], on=[\"pricedate\", \"hour\", \"node_id\"])\n",
    "    .assign(\n",
    "        gross_pl=lambda x: x.eval(\"- rtda * bidvolume\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# negative because we minimized negative profits\n",
    "- output[\"gross_pl\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Constraint Analysis\n",
    "\n",
    "Let's look at which constraints were binding and how \"expensive\" these imposed limits were"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binding = all_shadows[\"shadow_price\"] > 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# show 20 most painful constraints\n",
    "all_shadows.loc[binding, :].sort_values(\"shadow_price\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Corner solution\n",
    "\n",
    "The maximum position size we allowed in our algorithm was 5 units/node/hour\n",
    "\n",
    "The total number of bids we allow in any day is 500\n",
    "\n",
    "First, we verify that we did reach the 500 bids/day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bids.groupby(\"pricedate\").bid.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, let's see how many non-zero nodes were bid on each day\n",
    "\n",
    "If this is 100 then that means we bid the maximum 5 units on 100 nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    all_bids\n",
    "    .groupby(\"pricedate\")\n",
    "    .apply(lambda x: x.query(\"bid > 1e-3\").shape[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Notice that in each day, we bid 100 different positions, each at a volume of 5 units\n",
    "\n",
    "Because these were our constraints, this is known as a corner solution\n",
    "\n",
    "The linear program went all the way to the constraint for both the total bids per day and total bids per hour per node\n",
    "\n",
    "This resulted in a portfolio that was less diverse than may be optimal if we were to take into account other risk factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One very common risk factor that is used in portfolio optimization is the covariance of expected returns across positions\n",
    "\n",
    "The full covariance structure is an inherently quadratic statistic and thus cannot be naturally included in our linear program\n",
    "\n",
    "We would need to extend our framework to allow for a quadradtic objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In future lectures we will study quadratic programming and formulate a new objective that seeks to minimize a variance adjusted negative return\n",
    "\n",
    "This is known as \"modern portfolio theory\" or Markowitz porftolio theory and was part of why Harry Markowitz earned a Nobel price in economics in 1990"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "css",
   "language": "python",
   "name": "css"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
